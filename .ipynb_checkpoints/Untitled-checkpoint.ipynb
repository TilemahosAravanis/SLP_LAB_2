{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6a8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "\n",
    "import string\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f38fc",
   "metadata": {},
   "source": [
    "**Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd03bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data file\n",
    "\n",
    "# import tarfile\n",
    "\n",
    "# with tarfile.open(\"./usc.tgz\", \"r\") as tf:\n",
    "#    i=0\n",
    "#    for member in tf.getmembers():\n",
    "#        tf.extract(member=member, path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be008fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./usc/filesets/training.txt ./data/train/train_uttids.txt\n",
    "!cp ./usc/filesets/testing.txt ./data/test/test_uttids.txt\n",
    "!cp ./usc/filesets/validation.txt ./data/dev/dev_uttids.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b96beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5882b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/train/train_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61e5cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/test/test_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75081b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/dev_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/dev/dev_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "139e3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14e303cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_wav.scp\",'w') as f:\n",
    "    with open('./data/train/train_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7a6f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_wav.scp\",'w') as f:\n",
    "    with open('./data/test/test_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1056e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/dev_wav.scp\",'w') as f:\n",
    "    with open('./data/dev/dev_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac956f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f508fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text,punct_list):\n",
    "    for punc in punct_list:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "s = string.punctuation\n",
    "punct_list = s.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd52f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_text.txt\",'w') as f:\n",
    "        with open('./data/train/train_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "244094b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_text.txt\",'w') as f:\n",
    "        with open('./data/test/test_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a61e1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/dev_text.txt\",'w') as f:\n",
    "        with open('./data/dev/dev_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5229b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words --> phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca9dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict = {}\n",
    "with open('./usc/lexicon.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        word = line.split()[0].lower()\n",
    "        phon = ''\n",
    "        for words in line.split()[1:-1]:\n",
    "            phon = phon + str(\"{} \".format(words)) \n",
    "        phon = phon + str(\"{}\".format(line.split()[-1])) \n",
    "        Dict[word] = phon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff8d3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/dev_text2.txt\",'w') as out_f:\n",
    "        with open('./data/dev/dev_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abbfe862",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_text2.txt\",'w') as out_f:\n",
    "        with open('./data/train/train_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94de5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_text2.txt\",'w') as out_f:\n",
    "        with open('./data/test/test_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69869bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"./data/train/train_text.txt\")\n",
    "os.remove(\"./data/test/test_text.txt\")\n",
    "os.remove(\"./data/dev/dev_text.txt\")\n",
    "\n",
    "os.rename(\"./data/train/train_text2.txt\", \"./data/train/train_text.txt\")\n",
    "os.rename(\"./data/test/test_text2.txt\", \"./data/test/test_text.txt\")\n",
    "os.rename(\"./data/dev/dev_text2.txt\", \"./data/dev/dev_text.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d0348",
   "metadata": {},
   "source": [
    "**Main Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d8a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'steps/steps': File exists\n",
      "ln: failed to create symbolic link 'utils/utils': File exists\n",
      "mkdir: cannot create directory ‘./local’: File exists\n",
      "mkdir: cannot create directory ‘./conf’: File exists\n",
      "mkdir: cannot create directory ‘./data/lang’: File exists\n",
      "mkdir: cannot create directory ‘./data/local’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/dict’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/lm_tmp’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/nist_lm’: File exists\n",
      "total 132\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   698 Μαΐ  18 15:16 build.sh\n",
      "-rw-rw-r-- 1 tilemahos tilemahos  1318 Μαΐ  18 14:10 cmd.sh\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   300 Μαΐ  18 15:20 compile.sh\n",
      "drwxrwxr-x 2 tilemahos tilemahos  4096 Μαΐ  18 14:10 conf\n",
      "drwxrwxr-x 9 tilemahos tilemahos  4096 Μαΐ  19 13:59 data\n",
      "drwxrwxr-x 4 tilemahos tilemahos  4096 Μαΐ  19 14:12 exp\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   239 Μαΐ  19 12:53 frames.sh\n",
      "drwxrwxr-x 6 tilemahos tilemahos  4096 Μαΐ  18 14:10 jup_notebook\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   136 Μαΐ  18 17:59 L_creation.sh\n",
      "-rw-rw-r-- 1 tilemahos tilemahos     0 Μαΐ  18 14:10 lm\n",
      "drwxrwxr-x 2 tilemahos tilemahos  4096 Μαΐ  19 14:41 local\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   449 Μαΐ  18 14:19 path.sh\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   625 Μαΐ  19 12:23 perplexity.sh\n",
      "lrwxrwxrwx 1 tilemahos tilemahos    54 Μαΐ  19 12:56 steps -> /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/steps\n",
      "-rwxrwxr-x 1 tilemahos tilemahos  2581 Μαΐ  19 14:09 timit_format_data.sh\n",
      "-rw-rw-r-- 1 tilemahos tilemahos 66777 Μαΐ  19 14:40 Untitled.ipynb\n",
      "drwxrwxr-x 4 tilemahos tilemahos  4096 Μαΐ  18 14:10 usc\n",
      "lrwxrwxrwx 1 tilemahos tilemahos    54 Μαΐ  19 12:56 utils -> /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/utils\n",
      "-rw-rw-r-- 1 tilemahos tilemahos  4144 Μαΐ  18 14:10 val_wav.scp\n"
     ]
    }
   ],
   "source": [
    "# 4.1\n",
    "\n",
    "# !!!!! Insert your path in path.sh and the commands below !!!!!\n",
    "\n",
    "# soft links\n",
    "!ln -s /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/steps steps # /home/anthi/jupyter/kaldi/egs/wsj/s5/steps steps \n",
    "!ln -s /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/utils utils # /home/anthi/jupyter/kaldi/egs/wsj/s5/utils utils\n",
    "\n",
    "!mkdir ./local\n",
    "!ln -s /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/steps/score_kaldi.sh ./local/score.sh # /home/anthi/jupyter/kaldi/egs/wsj/s5/steps/score_kaldi.sh ./local/score_kaldi.sh \n",
    "\n",
    "!mkdir ./conf\n",
    "!touch ./conf/mfcc.conf\n",
    "\n",
    "!mkdir ./data/lang\n",
    "!mkdir ./data/local\n",
    "!mkdir ./data/local/dict\n",
    "!mkdir ./data/local/lm_tmp\n",
    "!mkdir ./data/local/nist_lm\n",
    "\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce368782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.1\n",
    "\n",
    "with open(\"./data/local/dict/silence_phones.txt\",'w') as f:\n",
    "    f.write('sil\\n')\n",
    "    \n",
    "with open(\"./data/local/dict/optional_silence.txt\",'w') as f:\n",
    "    f.write('sil\\n')\n",
    "\n",
    "s = set()\n",
    "with open(\"./data/local/dict/nonsilence_phones.txt\",'w') as f:\n",
    "    with open('./usc/lexicon.txt', 'r') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split()[1:]:\n",
    "                if word not in s:\n",
    "                    s.add(word)\n",
    "        s.remove('sil')\n",
    "        l = list(s)\n",
    "        l.sort()\n",
    "        for phoneme in l:\n",
    "            f.write('{}\\n'.format(phoneme))\n",
    "\n",
    "with open(\"./data/local/dict/lexicon.txt\",'w') as f:\n",
    "    with open(\"./data/local/dict/nonsilence_phones.txt\",'r') as file:\n",
    "        # reading each line\n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write('{} {}\\n'.format(word,word))\n",
    "        f.write('sil sil\\n')\n",
    "\n",
    "\n",
    "with open(\"./data/local/dict/lm_train.text\",'w') as out_f:\n",
    "    with open(\"./data/train/train_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "with open(\"./data/local/dict/lm_test.text\",'w') as out_f:\n",
    "    with open(\"./data/test/test_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "with open(\"./data/local/dict/lm_dev.text\",'w') as out_f:\n",
    "    with open(\"./data/dev/dev_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "!touch ./data/local/dict/extra_questions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "139402d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_train.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_train.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_test.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_test.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_val.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_val.ilm.gz already exists! either remove or rename it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./build.sh', 'arguments'], returncode=6)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.2.2\n",
    "\n",
    "subprocess.run([\"./build.sh\",\n",
    "                \"arguments\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d8a4e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inpfile: ./data/local/lm_tmp/uni_train.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n",
      "inpfile: ./data/local/lm_tmp/bi_train.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./compile.sh', 'arguments'], returncode=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"./compile.sh\",\n",
    "                \"arguments\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "145b41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tilemahos/Desktop/SLP_LAB/kaldi/egs/usc/utils/prepare_lang.sh ./data/local/dict <oov> ./data/local/lang data/lang\n",
      "Checking ./data/local/dict/silence_phones.txt ...\n",
      "--> reading ./data/local/dict/silence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/silence_phones.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/optional_silence.txt ...\n",
      "--> reading ./data/local/dict/optional_silence.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/optional_silence.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/nonsilence_phones.txt ...\n",
      "--> reading ./data/local/dict/nonsilence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/nonsilence_phones.txt is OK\n",
      "\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\n",
      "--> disjoint property is OK.\n",
      "\n",
      "Checking ./data/local/dict/lexicon.txt\n",
      "--> reading ./data/local/dict/lexicon.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/lexicon.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/lexiconp.txt\n",
      "--> reading ./data/local/dict/lexiconp.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/lexiconp.txt is OK\n",
      "\n",
      "Checking lexicon pair ./data/local/dict/lexicon.txt and ./data/local/dict/lexiconp.txt\n",
      "--> lexicon pair ./data/local/dict/lexicon.txt and ./data/local/dict/lexiconp.txt match\n",
      "\n",
      "Checking ./data/local/dict/extra_questions.txt ...\n",
      "--> ./data/local/dict/extra_questions.txt is empty (this is OK)\n",
      "--> SUCCESS [validating dictionary directory ./data/local/dict]\n",
      "\n",
      "prepare_lang.sh: validating output directory\n",
      "utils/validate_lang.pl data/lang\n",
      "Checking existence of separator file\n",
      "separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.\n",
      "Checking data/lang/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> found no unexplainable phones in phones.txt\n",
      "\n",
      "Checking data/lang/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 160 entry/entries in data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 2 entry/entries in data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang/phones/roots.txt\n",
      "--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt\n",
      "--> data/lang/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang/phones/sets.txt\n",
      "--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt\n",
      "--> data/lang/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 9 entry/entries in data/lang/phones/extra_questions.txt\n",
      "--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt\n",
      "--> data/lang/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 165 entry/entries in data/lang/phones/word_boundary.txt\n",
      "--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt\n",
      "--> data/lang/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 77 word/subword sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 44 word/subword sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang/oov.txt\n",
      "--> data/lang/oov.int corresponds to data/lang/oov.txt\n",
      "--> data/lang/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang/L.fst is olabel sorted\n",
      "--> data/lang/L_disambig.fst is olabel sorted\n",
      "--> SUCCESS [validating lang directory data/lang]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fstaddselfloops data/lang/phones/wdisambig_phones.int data/lang/phones/wdisambig_words.int \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./L_creation.sh'], returncode=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"./L_creation.sh\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ac54ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort ./data/dev/dev_wav.scp -o ./data/dev/dev_wav.scp; sort ./data/dev/dev_text.txt -o ./data/dev/dev_text.txt; sort ./data/dev/dev_utt2spk.txt -o ./data/dev/dev_utt2spk.txt\n",
    "!sort ./data/train/train_wav.scp -o ./data/train/train_wav.scp; sort ./data/train/train_text.txt -o ./data/train/train_text.txt; sort ./data/train/train_utt2spk.txt -o ./data/train/train_utt2spk.txt\n",
    "!sort ./data/test/test_wav.scp -o ./data/test/test_wav.scp; sort ./data/test/test_text.txt -o ./data/test/test_text.txt; sort ./data/test/test_utt2spk.txt -o ./data/test/test_utt2spk.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ad2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4699f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./utils/utt2spk_to_spk2utt.pl ./data/train/train_utt2spk.txt > ./data/train/train_spk2utt.txt\n",
    "!./utils/utt2spk_to_spk2utt.pl ./data/dev/dev_utt2spk.txt > ./data/dev/dev_spk2utt.txt\n",
    "!./utils/utt2spk_to_spk2utt.pl ./data/test/test_utt2spk.txt > ./data/test/test_spk2utt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e64d899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train, dev and test data\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/train\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/dev\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/test\n",
      "Preparing language models for test\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test_ug/words.txt - data/lang_test_ug/G.fst \n",
      "LOG (arpa2fst[5.5.1071~1-19185]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.1071~1-19185]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.1071~1-19185]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 1 to 1\n",
      "fstisstochastic data/lang_test_ug/G.fst \n",
      "0.000994972 0.000994972\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test_bg/words.txt - data/lang_test_bg/G.fst \n",
      "LOG (arpa2fst[5.5.1071~1-19185]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.1071~1-19185]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.1071~1-19185]:Read():arpa-file-parser.cc:149) Reading \\2-grams: section.\n",
      "WARNING (arpa2fst[5.5.1071~1-19185]:ConsumeNGram():arpa-lm-compiler.cc:313) line 52 [-2.82084\t<s> <s>] skipped: n-gram has invalid BOS/EOS placement\n",
      "LOG (arpa2fst[5.5.1071~1-19185]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 42 to 42\n",
      "fstisstochastic data/lang_test_bg/G.fst \n",
      "0.00142338 -0.0828663\n",
      "utils/validate_lang.pl data/lang_test_bg\n",
      "Checking existence of separator file\n",
      "separator file data/lang_test_bg/subword_separator.txt is empty or does not exist, deal in word case.\n",
      "Checking data/lang_test_bg/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_test_bg/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_test_bg/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> found no unexplainable phones in phones.txt\n",
      "\n",
      "Checking data/lang_test_bg/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang_test_bg/phones/context_indep.txt\n",
      "--> data/lang_test_bg/phones/context_indep.int corresponds to data/lang_test_bg/phones/context_indep.txt\n",
      "--> data/lang_test_bg/phones/context_indep.csl corresponds to data/lang_test_bg/phones/context_indep.txt\n",
      "--> data/lang_test_bg/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 160 entry/entries in data/lang_test_bg/phones/nonsilence.txt\n",
      "--> data/lang_test_bg/phones/nonsilence.int corresponds to data/lang_test_bg/phones/nonsilence.txt\n",
      "--> data/lang_test_bg/phones/nonsilence.csl corresponds to data/lang_test_bg/phones/nonsilence.txt\n",
      "--> data/lang_test_bg/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang_test_bg/phones/silence.txt\n",
      "--> data/lang_test_bg/phones/silence.int corresponds to data/lang_test_bg/phones/silence.txt\n",
      "--> data/lang_test_bg/phones/silence.csl corresponds to data/lang_test_bg/phones/silence.txt\n",
      "--> data/lang_test_bg/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_test_bg/phones/optional_silence.txt\n",
      "--> data/lang_test_bg/phones/optional_silence.int corresponds to data/lang_test_bg/phones/optional_silence.txt\n",
      "--> data/lang_test_bg/phones/optional_silence.csl corresponds to data/lang_test_bg/phones/optional_silence.txt\n",
      "--> data/lang_test_bg/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 2 entry/entries in data/lang_test_bg/phones/disambig.txt\n",
      "--> data/lang_test_bg/phones/disambig.int corresponds to data/lang_test_bg/phones/disambig.txt\n",
      "--> data/lang_test_bg/phones/disambig.csl corresponds to data/lang_test_bg/phones/disambig.txt\n",
      "--> data/lang_test_bg/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_test_bg/phones/roots.txt\n",
      "--> data/lang_test_bg/phones/roots.int corresponds to data/lang_test_bg/phones/roots.txt\n",
      "--> data/lang_test_bg/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_test_bg/phones/sets.txt\n",
      "--> data/lang_test_bg/phones/sets.int corresponds to data/lang_test_bg/phones/sets.txt\n",
      "--> data/lang_test_bg/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 9 entry/entries in data/lang_test_bg/phones/extra_questions.txt\n",
      "--> data/lang_test_bg/phones/extra_questions.int corresponds to data/lang_test_bg/phones/extra_questions.txt\n",
      "--> data/lang_test_bg/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 165 entry/entries in data/lang_test_bg/phones/word_boundary.txt\n",
      "--> data/lang_test_bg/phones/word_boundary.int corresponds to data/lang_test_bg/phones/word_boundary.txt\n",
      "--> data/lang_test_bg/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang_test_bg/phones/optional_silence.txt\n",
      "--> data/lang_test_bg/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang_test_bg/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang_test_bg/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang_test_bg/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang_test_bg/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang_test_bg/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang_test_bg/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 96 word/subword sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 36 word/subword sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang_test_bg/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_test_bg/oov.txt\n",
      "--> data/lang_test_bg/oov.int corresponds to data/lang_test_bg/oov.txt\n",
      "--> data/lang_test_bg/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang_test_bg/L.fst is olabel sorted\n",
      "--> data/lang_test_bg/L_disambig.fst is olabel sorted\n",
      "--> data/lang_test_bg/G.fst is ilabel sorted\n",
      "--> data/lang_test_bg/G.fst has 42 states\n",
      "fstdeterminizestar data/lang_test_bg/G.fst /dev/null \n",
      "--> data/lang_test_bg/G.fst is determinizable\n",
      "--> utils/lang/check_g_properties.pl successfully validated data/lang_test_bg/G.fst\n",
      "--> utils/lang/check_g_properties.pl succeeded.\n",
      "--> Testing determinizability of L_disambig . G\n",
      "fsttablecompose data/lang_test_bg/L_disambig.fst data/lang_test_bg/G.fst \n",
      "fstdeterminizestar \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> L_disambig . G is determinizable\n",
      "--> SUCCESS [validating lang directory data/lang_test_bg]\n",
      "utils/validate_lang.pl data/lang_test_ug\n",
      "Checking existence of separator file\n",
      "separator file data/lang_test_ug/subword_separator.txt is empty or does not exist, deal in word case.\n",
      "Checking data/lang_test_ug/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_test_ug/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_test_ug/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> found no unexplainable phones in phones.txt\n",
      "\n",
      "Checking data/lang_test_ug/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang_test_ug/phones/context_indep.txt\n",
      "--> data/lang_test_ug/phones/context_indep.int corresponds to data/lang_test_ug/phones/context_indep.txt\n",
      "--> data/lang_test_ug/phones/context_indep.csl corresponds to data/lang_test_ug/phones/context_indep.txt\n",
      "--> data/lang_test_ug/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_ug/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 160 entry/entries in data/lang_test_ug/phones/nonsilence.txt\n",
      "--> data/lang_test_ug/phones/nonsilence.int corresponds to data/lang_test_ug/phones/nonsilence.txt\n",
      "--> data/lang_test_ug/phones/nonsilence.csl corresponds to data/lang_test_ug/phones/nonsilence.txt\n",
      "--> data/lang_test_ug/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_ug/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang_test_ug/phones/silence.txt\n",
      "--> data/lang_test_ug/phones/silence.int corresponds to data/lang_test_ug/phones/silence.txt\n",
      "--> data/lang_test_ug/phones/silence.csl corresponds to data/lang_test_ug/phones/silence.txt\n",
      "--> data/lang_test_ug/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_ug/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_test_ug/phones/optional_silence.txt\n",
      "--> data/lang_test_ug/phones/optional_silence.int corresponds to data/lang_test_ug/phones/optional_silence.txt\n",
      "--> data/lang_test_ug/phones/optional_silence.csl corresponds to data/lang_test_ug/phones/optional_silence.txt\n",
      "--> data/lang_test_ug/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_ug/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 2 entry/entries in data/lang_test_ug/phones/disambig.txt\n",
      "--> data/lang_test_ug/phones/disambig.int corresponds to data/lang_test_ug/phones/disambig.txt\n",
      "--> data/lang_test_ug/phones/disambig.csl corresponds to data/lang_test_ug/phones/disambig.txt\n",
      "--> data/lang_test_ug/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_ug/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_test_ug/phones/roots.txt\n",
      "--> data/lang_test_ug/phones/roots.int corresponds to data/lang_test_ug/phones/roots.txt\n",
      "--> data/lang_test_ug/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_ug/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_test_ug/phones/sets.txt\n",
      "--> data/lang_test_ug/phones/sets.int corresponds to data/lang_test_ug/phones/sets.txt\n",
      "--> data/lang_test_ug/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_ug/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 9 entry/entries in data/lang_test_ug/phones/extra_questions.txt\n",
      "--> data/lang_test_ug/phones/extra_questions.int corresponds to data/lang_test_ug/phones/extra_questions.txt\n",
      "--> data/lang_test_ug/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_ug/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 165 entry/entries in data/lang_test_ug/phones/word_boundary.txt\n",
      "--> data/lang_test_ug/phones/word_boundary.int corresponds to data/lang_test_ug/phones/word_boundary.txt\n",
      "--> data/lang_test_ug/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang_test_ug/phones/optional_silence.txt\n",
      "--> data/lang_test_ug/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang_test_ug/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang_test_ug/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang_test_ug/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang_test_ug/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang_test_ug/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang_test_ug/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 17 word/subword sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 19 word/subword sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang_test_ug/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_test_ug/oov.txt\n",
      "--> data/lang_test_ug/oov.int corresponds to data/lang_test_ug/oov.txt\n",
      "--> data/lang_test_ug/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang_test_ug/L.fst is olabel sorted\n",
      "--> data/lang_test_ug/L_disambig.fst is olabel sorted\n",
      "--> data/lang_test_ug/G.fst is ilabel sorted\n",
      "--> data/lang_test_ug/G.fst has 1 states\n",
      "fstdeterminizestar data/lang_test_ug/G.fst /dev/null \n",
      "--> data/lang_test_ug/G.fst is determinizable\n",
      "--> utils/lang/check_g_properties.pl successfully validated data/lang_test_ug/G.fst\n",
      "--> utils/lang/check_g_properties.pl succeeded.\n",
      "--> Testing determinizability of L_disambig . G\n",
      "fsttablecompose data/lang_test_ug/L_disambig.fst data/lang_test_ug/G.fst \n",
      "fstdeterminizestar \n",
      "--> L_disambig . G is determinizable\n",
      "--> SUCCESS [validating lang directory data/lang_test_ug]\n",
      "Succeeded in formatting data.\n"
     ]
    }
   ],
   "source": [
    "!./timit_format_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc1c5c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Calculating perplexity for the unigram model of the dev set #\n",
      "inpfile: uni_dev.ilm.gz\n",
      "outfile: uni_dev.ilm.blm\n",
      "evalfile: ../dict/lm_dev.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "DEBUG_LEVEL:0/1 Failed to open uni_dev.ilm.gz\n",
      "# Calculating perplexity for the bigram model of the dev set #\n",
      "inpfile: bi_dev.ilm.gz\n",
      "outfile: bi_dev.ilm.blm\n",
      "evalfile: ../dict/lm_dev.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "DEBUG_LEVEL:0/1 Failed to open bi_dev.ilm.gz\n",
      "# Calculating perplexity for the unigram model of the test set #\n",
      "inpfile: uni_test.ilm.gz\n",
      "outfile: uni_test.ilm.blm\n",
      "evalfile: ../dict/lm_test.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=12795 PP=31.87 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n",
      "# Calculating perplexity for the bigram model of the test set #\n",
      "inpfile: bi_test.ilm.gz\n",
      "outfile: bi_test.ilm.blm\n",
      "evalfile: ../dict/lm_test.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=12795 PP=13.26 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n"
     ]
    }
   ],
   "source": [
    "!./perplexity.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9da3924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steps/make_mfcc.sh ./data/train\n",
      "./steps/make_mfcc.sh: moving ./data/train/feats.scp to ./data/train/.backup\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory ./data/train\n",
      "./steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "./steps/make_mfcc.sh: Succeeded creating MFCC features for train\n",
      "./steps/make_mfcc.sh ./data/test\n",
      "./steps/make_mfcc.sh: moving ./data/test/feats.scp to ./data/test/.backup\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory ./data/test\n",
      "./steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "./steps/make_mfcc.sh: Succeeded creating MFCC features for test\n",
      "./steps/make_mfcc.sh ./data/dev\n",
      "./steps/make_mfcc.sh: moving ./data/dev/feats.scp to ./data/dev/.backup\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory ./data/dev\n",
      "./steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "./steps/make_mfcc.sh: Succeeded creating MFCC features for dev\n"
     ]
    }
   ],
   "source": [
    "!./steps/make_mfcc.sh ./data/train\n",
    "!./steps/make_mfcc.sh ./data/test\n",
    "!./steps/make_mfcc.sh ./data/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd2c68e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steps/compute_cmvn_stats.sh ./data/train\n",
      "Succeeded creating CMVN stats for train\n",
      "./steps/compute_cmvn_stats.sh ./data/test\n",
      "Succeeded creating CMVN stats for test\n",
      "./steps/compute_cmvn_stats.sh ./data/dev\n",
      "Succeeded creating CMVN stats for dev\n"
     ]
    }
   ],
   "source": [
    "!./steps/compute_cmvn_stats.sh ./data/train # Cepstral Mean and Variance Normalization\n",
    "!./steps/compute_cmvn_stats.sh ./data/test\n",
    "!./steps/compute_cmvn_stats.sh ./data/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"./frames.sh\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a009d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0c7b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steps/train_mono.sh ./data/train ./data/lang_test_bg ./exp/mono_bg\n",
      "./steps/train_mono.sh: Initializing monophone system.\n",
      "./steps/train_mono.sh: Compiling training graphs\n",
      "./steps/train_mono.sh: Aligning data equally (pass 0)\n",
      "./steps/train_mono.sh: Pass 1\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 2\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 3\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 4\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 5\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 6\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 7\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 8\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 9\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 10\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 11\n",
      "./steps/train_mono.sh: Pass 12\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 13\n",
      "./steps/train_mono.sh: Pass 14\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 15\n",
      "./steps/train_mono.sh: Pass 16\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 17\n",
      "./steps/train_mono.sh: Pass 18\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 19\n",
      "./steps/train_mono.sh: Pass 20\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 21\n",
      "./steps/train_mono.sh: Pass 22\n",
      "./steps/train_mono.sh: Pass 23\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 24\n",
      "./steps/train_mono.sh: Pass 25\n",
      "./steps/train_mono.sh: Pass 26\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 27\n",
      "./steps/train_mono.sh: Pass 28\n",
      "./steps/train_mono.sh: Pass 29\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 30\n",
      "./steps/train_mono.sh: Pass 31\n",
      "./steps/train_mono.sh: Pass 32\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 33\n",
      "./steps/train_mono.sh: Pass 34\n",
      "./steps/train_mono.sh: Pass 35\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 36\n",
      "./steps/train_mono.sh: Pass 37\n",
      "./steps/train_mono.sh: Pass 38\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 39\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl ./data/lang_test_bg ./exp/mono_bg\n",
      "run.pl: job failed, log is in ./exp/mono_bg/log/analyze_alignments.log\n",
      "steps/diagnostic/analyze_alignments.sh: analyze_phone_length_stats.py failed, but ignoring the error (it's just for diagnostics)\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in ./exp/mono_bg/log/analyze_alignments.log\n",
      "6 warnings in ./exp/mono_bg/log/init.log\n",
      "121 warnings in ./exp/mono_bg/log/update.*.log\n",
      "191 warnings in ./exp/mono_bg/log/acc.*.*.log\n",
      "2716 warnings in ./exp/mono_bg/log/align.*.*.log\n",
      "./exp/mono_bg: nj=4 align prob=-83.61 over 1.66h [retry=1.2%, fail=0.2%] states=125 gauss=997\n",
      "./steps/train_mono.sh: Done training monophone system in ./exp/mono_bg\n",
      "./steps/train_mono.sh ./data/train ./data/lang_test_ug ./exp/mono_ug\n",
      "./steps/train_mono.sh: Initializing monophone system.\n",
      "./steps/train_mono.sh: Compiling training graphs\n",
      "./steps/train_mono.sh: Aligning data equally (pass 0)\n",
      "./steps/train_mono.sh: Pass 1\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 2\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 3\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 4\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 5\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 6\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 7\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 8\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 9\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 10\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 11\n",
      "./steps/train_mono.sh: Pass 12\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 13\n",
      "./steps/train_mono.sh: Pass 14\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 15\n",
      "./steps/train_mono.sh: Pass 16\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 17\n",
      "./steps/train_mono.sh: Pass 18\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 19\n",
      "./steps/train_mono.sh: Pass 20\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 21\n",
      "./steps/train_mono.sh: Pass 22\n",
      "./steps/train_mono.sh: Pass 23\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 24\n",
      "./steps/train_mono.sh: Pass 25\n",
      "./steps/train_mono.sh: Pass 26\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 27\n",
      "./steps/train_mono.sh: Pass 28\n",
      "./steps/train_mono.sh: Pass 29\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 30\n",
      "./steps/train_mono.sh: Pass 31\n",
      "./steps/train_mono.sh: Pass 32\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 33\n",
      "./steps/train_mono.sh: Pass 34\n",
      "./steps/train_mono.sh: Pass 35\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 36\n",
      "./steps/train_mono.sh: Pass 37\n",
      "./steps/train_mono.sh: Pass 38\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 39\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl ./data/lang_test_ug ./exp/mono_ug\n",
      "run.pl: job failed, log is in ./exp/mono_ug/log/analyze_alignments.log\n",
      "steps/diagnostic/analyze_alignments.sh: analyze_phone_length_stats.py failed, but ignoring the error (it's just for diagnostics)\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in ./exp/mono_ug/log/analyze_alignments.log\n",
      "191 warnings in ./exp/mono_ug/log/acc.*.*.log\n",
      "2716 warnings in ./exp/mono_ug/log/align.*.*.log\n",
      "121 warnings in ./exp/mono_ug/log/update.*.log\n",
      "6 warnings in ./exp/mono_ug/log/init.log\n",
      "./exp/mono_ug: nj=4 align prob=-83.61 over 1.66h [retry=1.2%, fail=0.2%] states=125 gauss=997\n",
      "./steps/train_mono.sh: Done training monophone system in ./exp/mono_ug\n"
     ]
    }
   ],
   "source": [
    "!./steps/train_mono.sh ./data/train ./data/lang_test_bg ./exp/mono_bg\n",
    "!./steps/train_mono.sh ./data/train ./data/lang_test_ug ./exp/mono_ug\n",
    "# align ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5be2137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils/mkgraph.sh: ./exp/mono_bg/graph_bg/HCLG.fst is up to date.\n",
      "utils/mkgraph.sh: ./exp/mono_ug/graph_ug/HCLG.fst is up to date.\n"
     ]
    }
   ],
   "source": [
    "# 4.4.2\n",
    "\n",
    "!utils/mkgraph.sh ./data/lang_test_bg ./exp/mono_bg ./exp/mono_bg/graph_bg\n",
    "!utils/mkgraph.sh ./data/lang_test_ug ./exp/mono_ug ./exp/mono_ug/graph_ug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bfcbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/decode.sh ./exp/mono_bg/graph_bg ./data/dev ./exp/mono_bg/decode_dev\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl ./exp/mono_bg/graph_bg ./exp/mono_bg/decode_dev\n",
      "run.pl: job failed, log is in ./exp/mono_bg/decode_dev/log/analyze_alignments.log\n",
      "local/score.sh --cmd run.pl ./data/dev ./exp/mono_bg/graph_bg ./exp/mono_bg/decode_dev\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "steps/decode.sh ./exp/mono_ug/graph_ug ./data/dev ./exp/mono_ug/decode_dev\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl ./exp/mono_ug/graph_ug ./exp/mono_ug/decode_dev\n",
      "run.pl: job failed, log is in ./exp/mono_ug/decode_dev/log/analyze_alignments.log\n",
      "local/score.sh --cmd run.pl ./data/dev ./exp/mono_ug/graph_ug ./exp/mono_ug/decode_dev\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "steps/decode.sh ./exp/mono_bg/graph_bg ./data/test ./exp/mono_bg/decode_test\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl ./exp/mono_bg/graph_bg ./exp/mono_bg/decode_test\n",
      "run.pl: job failed, log is in ./exp/mono_bg/decode_test/log/analyze_alignments.log\n",
      "local/score.sh --cmd run.pl ./data/test ./exp/mono_bg/graph_bg ./exp/mono_bg/decode_test\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "steps/decode.sh ./exp/mono_ug/graph_ug ./data/test ./exp/mono_ug/decode_test\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl ./exp/mono_ug/graph_ug ./exp/mono_ug/decode_test\n",
      "run.pl: job failed, log is in ./exp/mono_ug/decode_test/log/analyze_alignments.log\n",
      "local/score.sh --cmd run.pl ./data/test ./exp/mono_ug/graph_ug ./exp/mono_ug/decode_test\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n"
     ]
    }
   ],
   "source": [
    "# 4.4.3\n",
    "\n",
    "!steps/decode.sh ./exp/mono_bg/graph_bg ./data/dev ./exp/mono_bg/decode_dev\n",
    "!steps/decode.sh ./exp/mono_ug/graph_ug ./data/dev ./exp/mono_ug/decode_dev\n",
    "\n",
    "!steps/decode.sh ./exp/mono_bg/graph_bg ./data/test ./exp/mono_bg/decode_test\n",
    "!steps/decode.sh ./exp/mono_ug/graph_ug ./data/test ./exp/mono_ug/decode_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d0bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3823f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%WER 45.40 [ 2171 / 4782, 106 ins, 924 del, 1141 sub ] ./exp/mono_bg/decode_dev/wer_7_0.0\n",
      "%WER 51.99 [ 2486 / 4782, 79 ins, 1335 del, 1072 sub ] ./exp/mono_ug/decode_dev/wer_7_0.0\n",
      "%WER 44.98 [ 5590 / 12428, 190 ins, 2539 del, 2861 sub ] ./exp/mono_bg/decode_test/wer_7_0.0\n",
      "%WER 51.70 [ 6425 / 12428, 116 ins, 3699 del, 2610 sub ] ./exp/mono_ug/decode_test/wer_7_0.0\n"
     ]
    }
   ],
   "source": [
    "!cat ./exp/mono_bg/decode_dev/scoring_kaldi/best_wer \n",
    "!cat ./exp/mono_ug/decode_dev/scoring_kaldi/best_wer\n",
    "\n",
    "!cat ./exp/mono_bg/decode_test/scoring_kaldi/best_wer \n",
    "!cat ./exp/mono_ug/decode_test/scoring_kaldi/best_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779d95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa579fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/align_si.sh ./data/train ./data/lang_test_bg ./exp/mono_bg exp/mono_bg_ali\n",
      "steps/align_si.sh: feature type is delta\n",
      "steps/align_si.sh: aligning data in ./data/train using model from ./exp/mono_bg, putting alignments in exp/mono_bg_ali\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl ./data/lang_test_bg exp/mono_bg_ali\n",
      "run.pl: job failed, log is in exp/mono_bg_ali/log/analyze_alignments.log\n",
      "steps/diagnostic/analyze_alignments.sh: analyze_phone_length_stats.py failed, but ignoring the error (it's just for diagnostics)\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_bg_ali/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n",
      "steps/align_si.sh ./data/train ./data/lang_test_ug ./exp/mono_ug exp/mono_ug_ali\n",
      "steps/align_si.sh: feature type is delta\n",
      "steps/align_si.sh: aligning data in ./data/train using model from ./exp/mono_ug, putting alignments in exp/mono_ug_ali\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl ./data/lang_test_ug exp/mono_ug_ali\n",
      "run.pl: job failed, log is in exp/mono_ug_ali/log/analyze_alignments.log\n",
      "steps/diagnostic/analyze_alignments.sh: analyze_phone_length_stats.py failed, but ignoring the error (it's just for diagnostics)\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ug_ali/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n"
     ]
    }
   ],
   "source": [
    "!steps/align_si.sh ./data/train ./data/lang_test_bg ./exp/mono_bg exp/mono_bg_ali\n",
    "!steps/align_si.sh ./data/train ./data/lang_test_ug ./exp/mono_ug exp/mono_ug_ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd5eff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/train_deltas.sh 2000 10000 ./data/train ./data/lang_test_bg ./exp/mono_bg_ali ./exp/tri1_bg\n",
      "steps/train_deltas.sh: accumulating tree stats\n",
      "steps/train_deltas.sh: getting questions for tree-building, via clustering\n",
      "steps/train_deltas.sh: building the tree\n",
      "WARNING (gmm-init-model[5.5.1071~1-19185]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 \n",
      "** The warnings above about 'no stats' generally mean you have phones **\n",
      "** (or groups of phones) in your phone set that had no corresponding data. **\n",
      "** You should probably figure out whether something went wrong, **\n",
      "** or whether your data just doesn't happen to have examples of those **\n",
      "** phones. **\n",
      "steps/train_deltas.sh: converting alignments from ./exp/mono_bg_ali to use current tree\n",
      "steps/train_deltas.sh: compiling graphs of transcripts\n",
      "steps/train_deltas.sh: training pass 1\n",
      "steps/train_deltas.sh: training pass 2\n",
      "steps/train_deltas.sh: training pass 3\n",
      "steps/train_deltas.sh: training pass 4\n",
      "steps/train_deltas.sh: training pass 5\n",
      "steps/train_deltas.sh: training pass 6\n",
      "steps/train_deltas.sh: training pass 7\n",
      "steps/train_deltas.sh: training pass 8\n",
      "steps/train_deltas.sh: training pass 9\n",
      "steps/train_deltas.sh: training pass 10\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 11\n",
      "steps/train_deltas.sh: training pass 12\n",
      "steps/train_deltas.sh: training pass 13\n",
      "steps/train_deltas.sh: training pass 14\n",
      "steps/train_deltas.sh: training pass 15\n",
      "steps/train_deltas.sh: training pass 16\n",
      "steps/train_deltas.sh: training pass 17\n",
      "steps/train_deltas.sh: training pass 18\n",
      "steps/train_deltas.sh: training pass 19\n",
      "steps/train_deltas.sh: training pass 20\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 21\n",
      "steps/train_deltas.sh: training pass 22\n",
      "steps/train_deltas.sh: training pass 23\n",
      "steps/train_deltas.sh: training pass 24\n",
      "steps/train_deltas.sh: training pass 25\n",
      "steps/train_deltas.sh: training pass 26\n",
      "steps/train_deltas.sh: training pass 27\n",
      "steps/train_deltas.sh: training pass 28\n",
      "steps/train_deltas.sh: training pass 29\n",
      "steps/train_deltas.sh: training pass 30\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 31\n",
      "steps/train_deltas.sh: training pass 32\n",
      "steps/train_deltas.sh: training pass 33\n",
      "steps/train_deltas.sh: training pass 34\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl ./data/lang_test_bg ./exp/tri1_bg\n",
      "run.pl: job failed, log is in ./exp/tri1_bg/log/analyze_alignments.log\n",
      "steps/diagnostic/analyze_alignments.sh: analyze_phone_length_stats.py failed, but ignoring the error (it's just for diagnostics)\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in ./exp/tri1_bg/log/analyze_alignments.log\n",
      "113 warnings in ./exp/tri1_bg/log/update.*.log\n",
      "51 warnings in ./exp/tri1_bg/log/align.*.*.log\n",
      "74 warnings in ./exp/tri1_bg/log/init_model.log\n",
      "1 warnings in ./exp/tri1_bg/log/questions.log\n",
      "1 warnings in ./exp/tri1_bg/log/build_tree.log\n",
      "93 warnings in ./exp/tri1_bg/log/acc.*.*.log\n",
      "./exp/tri1_bg: nj=4 align prob=-79.66 over 1.66h [retry=0.7%, fail=0.2%] states=960 gauss=10035 tree-impr=5.72\n",
      "steps/train_deltas.sh: Done training system with delta+delta-delta features in ./exp/tri1_bg\n",
      "steps/train_deltas.sh 2000 10000 ./data/train ./data/lang_test_ug ./exp/mono_ug_ali ./exp/tri1_ug\n",
      "steps/train_deltas.sh: accumulating tree stats\n",
      "steps/train_deltas.sh: getting questions for tree-building, via clustering\n",
      "steps/train_deltas.sh: building the tree\n",
      "WARNING (gmm-init-model[5.5.1071~1-19185]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 \n",
      "** The warnings above about 'no stats' generally mean you have phones **\n",
      "** (or groups of phones) in your phone set that had no corresponding data. **\n",
      "** You should probably figure out whether something went wrong, **\n",
      "** or whether your data just doesn't happen to have examples of those **\n",
      "** phones. **\n",
      "steps/train_deltas.sh: converting alignments from ./exp/mono_ug_ali to use current tree\n",
      "steps/train_deltas.sh: compiling graphs of transcripts\n",
      "steps/train_deltas.sh: training pass 1\n",
      "steps/train_deltas.sh: training pass 2\n",
      "steps/train_deltas.sh: training pass 3\n",
      "steps/train_deltas.sh: training pass 4\n",
      "steps/train_deltas.sh: training pass 5\n",
      "steps/train_deltas.sh: training pass 6\n",
      "steps/train_deltas.sh: training pass 7\n",
      "steps/train_deltas.sh: training pass 8\n",
      "steps/train_deltas.sh: training pass 9\n",
      "steps/train_deltas.sh: training pass 10\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 11\n",
      "steps/train_deltas.sh: training pass 12\n",
      "steps/train_deltas.sh: training pass 13\n",
      "steps/train_deltas.sh: training pass 14\n",
      "steps/train_deltas.sh: training pass 15\n",
      "steps/train_deltas.sh: training pass 16\n",
      "steps/train_deltas.sh: training pass 17\n",
      "steps/train_deltas.sh: training pass 18\n",
      "steps/train_deltas.sh: training pass 19\n",
      "steps/train_deltas.sh: training pass 20\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 21\n",
      "steps/train_deltas.sh: training pass 22\n",
      "steps/train_deltas.sh: training pass 23\n",
      "steps/train_deltas.sh: training pass 24\n",
      "steps/train_deltas.sh: training pass 25\n",
      "steps/train_deltas.sh: training pass 26\n",
      "steps/train_deltas.sh: training pass 27\n",
      "steps/train_deltas.sh: training pass 28\n",
      "steps/train_deltas.sh: training pass 29\n",
      "steps/train_deltas.sh: training pass 30\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 31\n",
      "steps/train_deltas.sh: training pass 32\n",
      "steps/train_deltas.sh: training pass 33\n",
      "steps/train_deltas.sh: training pass 34\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl ./data/lang_test_ug ./exp/tri1_ug\n",
      "run.pl: job failed, log is in ./exp/tri1_ug/log/analyze_alignments.log\n",
      "steps/diagnostic/analyze_alignments.sh: analyze_phone_length_stats.py failed, but ignoring the error (it's just for diagnostics)\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in ./exp/tri1_ug/log/analyze_alignments.log\n",
      "1 warnings in ./exp/tri1_ug/log/build_tree.log\n",
      "93 warnings in ./exp/tri1_ug/log/acc.*.*.log\n",
      "51 warnings in ./exp/tri1_ug/log/align.*.*.log\n",
      "113 warnings in ./exp/tri1_ug/log/update.*.log\n",
      "74 warnings in ./exp/tri1_ug/log/init_model.log\n",
      "1 warnings in ./exp/tri1_ug/log/questions.log\n",
      "./exp/tri1_ug: nj=4 align prob=-79.66 over 1.66h [retry=0.7%, fail=0.2%] states=960 gauss=10035 tree-impr=5.72\n",
      "steps/train_deltas.sh: Done training system with delta+delta-delta features in ./exp/tri1_ug\n"
     ]
    }
   ],
   "source": [
    "!steps/train_deltas.sh 2000 10000 ./data/train ./data/lang_test_bg ./exp/mono_bg_ali ./exp/tri1_bg\n",
    "!steps/train_deltas.sh 2000 10000 ./data/train ./data/lang_test_ug ./exp/mono_ug_ali ./exp/tri1_ug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae6579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils/mkgraph.sh: ./exp/tri1_bg/graph_bg/HCLG.fst is up to date.\n",
      "utils/mkgraph.sh: ./exp/tri1_ug/graph_ug/HCLG.fst is up to date.\n"
     ]
    }
   ],
   "source": [
    "!utils/mkgraph.sh ./data/lang_test_bg ./exp/tri1_bg ./exp/tri1_bg/graph_bg\n",
    "!utils/mkgraph.sh ./data/lang_test_ug ./exp/tri1_ug ./exp/tri1_ug/graph_ug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5992e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/decode.sh ./exp/tri1_bg/graph_bg ./data/dev ./exp/tri1_bg/decode_dev\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl ./exp/tri1_bg/graph_bg ./exp/tri1_bg/decode_dev\n",
      "run.pl: job failed, log is in ./exp/tri1_bg/decode_dev/log/analyze_alignments.log\n",
      "local/score.sh --cmd run.pl ./data/dev ./exp/tri1_bg/graph_bg ./exp/tri1_bg/decode_dev\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "steps/decode.sh ./exp/tri1_ug/graph_ug ./data/dev ./exp/tri1_ug/decode_dev\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl ./exp/tri1_ug/graph_ug ./exp/tri1_ug/decode_dev\n",
      "run.pl: job failed, log is in ./exp/tri1_ug/decode_dev/log/analyze_alignments.log\n",
      "local/score.sh --cmd run.pl ./data/dev ./exp/tri1_ug/graph_ug ./exp/tri1_ug/decode_dev\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "steps/decode.sh ./exp/tri1_bg/graph_bg ./data/test ./exp/tri1_bg/decode_test\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl ./exp/tri1_bg/graph_bg ./exp/tri1_bg/decode_test\n",
      "run.pl: job failed, log is in ./exp/tri1_bg/decode_test/log/analyze_alignments.log\n",
      "local/score.sh --cmd run.pl ./data/test ./exp/tri1_bg/graph_bg ./exp/tri1_bg/decode_test\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "steps/decode.sh ./exp/tri1_ug/graph_ug ./data/test ./exp/tri1_ug/decode_test\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl ./exp/tri1_ug/graph_ug ./exp/tri1_ug/decode_test\n",
      "run.pl: job failed, log is in ./exp/tri1_ug/decode_test/log/analyze_alignments.log\n",
      "local/score.sh --cmd run.pl ./data/test ./exp/tri1_ug/graph_ug ./exp/tri1_ug/decode_test\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n"
     ]
    }
   ],
   "source": [
    "!steps/decode.sh ./exp/tri1_bg/graph_bg ./data/dev ./exp/tri1_bg/decode_dev\n",
    "!steps/decode.sh ./exp/tri1_ug/graph_ug ./data/dev ./exp/tri1_ug/decode_dev\n",
    "\n",
    "!steps/decode.sh ./exp/tri1_bg/graph_bg ./data/test ./exp/tri1_bg/decode_test\n",
    "!steps/decode.sh ./exp/tri1_ug/graph_ug ./data/test ./exp/tri1_ug/decode_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6133a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%WER 35.88 [ 1716 / 4782, 245 ins, 421 del, 1050 sub ] ./exp/tri1_bg/decode_dev/wer_8_0.0\n",
      "%WER 39.27 [ 1878 / 4782, 268 ins, 524 del, 1086 sub ] ./exp/tri1_ug/decode_dev/wer_7_0.0\n",
      "%WER 34.79 [ 4324 / 12428, 436 ins, 1270 del, 2618 sub ] ./exp/tri1_bg/decode_test/wer_8_0.0\n",
      "%WER 38.34 [ 4765 / 12428, 442 ins, 1685 del, 2638 sub ] ./exp/tri1_ug/decode_test/wer_7_0.0\n"
     ]
    }
   ],
   "source": [
    "!cat ./exp/tri1_bg/decode_dev/scoring_kaldi/best_wer \n",
    "!cat ./exp/tri1_ug/decode_dev/scoring_kaldi/best_wer\n",
    "\n",
    "!cat ./exp/tri1_bg/decode_test/scoring_kaldi/best_wer \n",
    "!cat ./exp/tri1_ug/decode_test/scoring_kaldi/best_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f33ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
