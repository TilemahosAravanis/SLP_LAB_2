{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6a8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "\n",
    "import string\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f38fc",
   "metadata": {},
   "source": [
    "**Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd03bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data file\n",
    "\n",
    "# import tarfile\n",
    "\n",
    "# with tarfile.open(\"./usc.tgz\", \"r\") as tf:\n",
    "#    i=0\n",
    "#    for member in tf.getmembers():\n",
    "#        tf.extract(member=member, path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be008fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./usc/filesets/training.txt ./data/train/train_uttids.txt\n",
    "!cp ./usc/filesets/testing.txt ./data/test/test_uttids.txt\n",
    "!cp ./usc/filesets/validation.txt ./data/dev/dev_uttids.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b96beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5882b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/train/train_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e5cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/test/test_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75081b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/dev_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/dev/dev_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139e3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e303cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_wav.scp\",'w') as f:\n",
    "    with open('./data/train/train_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a6f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_wav.scp\",'w') as f:\n",
    "    with open('./data/test/test_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1056e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/dev_wav.scp\",'w') as f:\n",
    "    with open('./data/dev/dev_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac956f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f508fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text,punct_list):\n",
    "    for punc in punct_list:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "s = string.punctuation\n",
    "punct_list = s.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd52f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_text.txt\",'w') as f:\n",
    "        with open('./data/train/train_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "244094b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_text.txt\",'w') as f:\n",
    "        with open('./data/test/test_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a61e1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/dev_text.txt\",'w') as f:\n",
    "        with open('./data/dev/dev_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5229b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words --> phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca9dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict = {}\n",
    "with open('./usc/lexicon.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        word = line.split()[0].lower()\n",
    "        phon = ''\n",
    "        for words in line.split()[1:-1]:\n",
    "            phon = phon + str(\"{} \".format(words)) \n",
    "        phon = phon + str(\"{}\".format(line.split()[-1])) \n",
    "        Dict[word] = phon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8d3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/dev_text2.txt\",'w') as out_f:\n",
    "        with open('./data/dev/dev_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abbfe862",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_text2.txt\",'w') as out_f:\n",
    "        with open('./data/train/train_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94de5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_text2.txt\",'w') as out_f:\n",
    "        with open('./data/test/test_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69869bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"./data/train/train_text.txt\")\n",
    "os.remove(\"./data/test/test_text.txt\")\n",
    "os.remove(\"./data/dev/dev_text.txt\")\n",
    "\n",
    "os.rename(\"./data/train/train_text2.txt\", \"./data/train/train_text.txt\")\n",
    "os.rename(\"./data/test/test_text2.txt\", \"./data/test/test_text.txt\")\n",
    "os.rename(\"./data/dev/dev_text2.txt\", \"./data/dev/dev_text.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d0348",
   "metadata": {},
   "source": [
    "**Main Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3d8a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'steps/steps': File exists\n",
      "ln: failed to create symbolic link 'utils/utils': File exists\n",
      "mkdir: cannot create directory ‘./local’: File exists\n",
      "ln: failed to create symbolic link './local/score_kaldi.sh': File exists\n",
      "mkdir: cannot create directory ‘./conf’: File exists\n",
      "mkdir: cannot create directory ‘./data/lang’: File exists\n",
      "mkdir: cannot create directory ‘./data/local’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/dict’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/lm_tmp’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/nist_lm’: File exists\n",
      "total 100\n",
      "-rwxrwxr-x 1 anthi anthi   698 Μαΐ  18 19:47 build.sh\n",
      "-rw-rw-r-- 1 anthi anthi  1318 Μαΐ  18 19:26 cmd.sh\n",
      "-rwxrwxr-x 1 anthi anthi   300 Μαΐ  18 19:26 compile.sh\n",
      "drwxrwxr-x 2 anthi anthi  4096 Μαΐ  18 19:26 conf\n",
      "drwxrwxr-x 8 anthi anthi  4096 Μαΐ  18 19:54 data\n",
      "-rwxrwxr-x 1 anthi anthi   136 Μαΐ  18 19:26 L_creation.sh\n",
      "-rw-rw-r-- 1 anthi anthi     0 Μαΐ  18 19:26 lm\n",
      "drwxrwxr-x 2 anthi anthi  4096 Μαΐ  18 20:37 local\n",
      "-rwxrwxr-x 1 anthi anthi   410 Μαΐ  18 19:29 path.sh\n",
      "-rwxrwxr-x 1 anthi anthi   625 Μαΐ  18 21:18 perplexity.sh\n",
      "lrwxrwxrwx 1 anthi anthi    42 Μαΐ  18 19:53 steps -> /home/anthi/jupyter/kaldi/egs/wsj/s5/steps\n",
      "-rwxrwxr-x 1 anthi anthi  2526 Μαΐ  18 20:58 timit_format_data.sh\n",
      "-rw-rw-r-- 1 anthi anthi 48952 Μαΐ  18 23:14 Untitled.ipynb\n",
      "drwxrwxr-x 4 anthi anthi  4096 Μαΐ  18 19:26 usc\n",
      "lrwxrwxrwx 1 anthi anthi    42 Μαΐ  18 19:53 utils -> /home/anthi/jupyter/kaldi/egs/wsj/s5/utils\n",
      "-rw-rw-r-- 1 anthi anthi  4144 Μαΐ  18 19:26 val_wav.scp\n"
     ]
    }
   ],
   "source": [
    "# 4.1\n",
    "\n",
    "# !!!!! Insert your path in path.sh and the commands below !!!!!\n",
    "\n",
    "# soft links\n",
    "!ln -s /home/anthi/jupyter/kaldi/egs/wsj/s5/steps steps \n",
    "!ln -s /home/anthi/jupyter/kaldi/egs/wsj/s5/utils utils\n",
    "\n",
    "!mkdir ./local\n",
    "!ln -s /home/anthi/jupyter/kaldi/egs/wsj/s5/steps/score_kaldi.sh ./local/score_kaldi.sh\n",
    "\n",
    "!mkdir ./conf\n",
    "!touch ./conf/mfcc.conf\n",
    "\n",
    "!mkdir ./data/lang\n",
    "!mkdir ./data/local\n",
    "!mkdir ./data/local/dict\n",
    "!mkdir ./data/local/lm_tmp\n",
    "!mkdir ./data/local/nist_lm\n",
    "\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce368782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.1\n",
    "\n",
    "with open(\"./data/local/dict/silence_phones.txt\",'w') as f:\n",
    "    f.write('sil\\n')\n",
    "    \n",
    "with open(\"./data/local/dict/optional_silence.txt\",'w') as f:\n",
    "    f.write('sil\\n')\n",
    "\n",
    "s = set()\n",
    "with open(\"./data/local/dict/nonsilence_phones.txt\",'w') as f:\n",
    "    with open('./usc/lexicon.txt', 'r') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split()[1:]:\n",
    "                if word not in s:\n",
    "                    s.add(word)\n",
    "        s.remove('sil')\n",
    "        l = list(s)\n",
    "        l.sort()\n",
    "        for phoneme in l:\n",
    "            f.write('{}\\n'.format(phoneme))\n",
    "\n",
    "with open(\"./data/local/dict/lexicon.txt\",'w') as f:\n",
    "    with open(\"./data/local/dict/nonsilence_phones.txt\",'r') as file:\n",
    "        # reading each line\n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write('{} {}\\n'.format(word,word))\n",
    "        f.write('sil sil\\n')\n",
    "\n",
    "\n",
    "with open(\"./data/local/dict/lm_train.text\",'w') as out_f:\n",
    "    with open(\"./data/train/train_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "with open(\"./data/local/dict/lm_test.text\",'w') as out_f:\n",
    "    with open(\"./data/test/test_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "with open(\"./data/local/dict/lm_dev.text\",'w') as out_f:\n",
    "    with open(\"./data/dev/dev_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "!touch ./data/local/dict/extra_questions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "139402d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_train.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_train.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_test.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_test.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_dev.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_dev.ilm.gz already exists! either remove or rename it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./build.sh', 'arguments'], returncode=6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.2.2\n",
    "\n",
    "subprocess.run([\"./build.sh\",\n",
    "                \"arguments\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b86e06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d8a4e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inpfile: ./data/local/lm_tmp/uni_train.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n",
      "inpfile: ./data/local/lm_tmp/bi_train.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./compile.sh', 'arguments'], returncode=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"./compile.sh\",\n",
    "                \"arguments\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4a5b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "145b41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anthi/jupyter/kaldi/egs/usc/utils/prepare_lang.sh ./data/local/dict <oov> ./data/local/lang data/lang\n",
      "Checking ./data/local/dict/silence_phones.txt ...\n",
      "--> reading ./data/local/dict/silence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/silence_phones.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/optional_silence.txt ...\n",
      "--> reading ./data/local/dict/optional_silence.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/optional_silence.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/nonsilence_phones.txt ...\n",
      "--> reading ./data/local/dict/nonsilence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/nonsilence_phones.txt is OK\n",
      "\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\n",
      "--> disjoint property is OK.\n",
      "\n",
      "Checking ./data/local/dict/lexicon.txt\n",
      "--> reading ./data/local/dict/lexicon.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/lexicon.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/lexiconp.txt\n",
      "--> reading ./data/local/dict/lexiconp.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/lexiconp.txt is OK\n",
      "\n",
      "Checking lexicon pair ./data/local/dict/lexicon.txt and ./data/local/dict/lexiconp.txt\n",
      "--> lexicon pair ./data/local/dict/lexicon.txt and ./data/local/dict/lexiconp.txt match\n",
      "\n",
      "Checking ./data/local/dict/extra_questions.txt ...\n",
      "--> ./data/local/dict/extra_questions.txt is empty (this is OK)\n",
      "--> SUCCESS [validating dictionary directory ./data/local/dict]\n",
      "\n",
      "prepare_lang.sh: validating output directory\n",
      "utils/validate_lang.pl data/lang\n",
      "Checking existence of separator file\n",
      "separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.\n",
      "Checking data/lang/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> found no unexplainable phones in phones.txt\n",
      "\n",
      "Checking data/lang/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 160 entry/entries in data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 2 entry/entries in data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang/phones/roots.txt\n",
      "--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt\n",
      "--> data/lang/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang/phones/sets.txt\n",
      "--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt\n",
      "--> data/lang/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 9 entry/entries in data/lang/phones/extra_questions.txt\n",
      "--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt\n",
      "--> data/lang/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 165 entry/entries in data/lang/phones/word_boundary.txt\n",
      "--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt\n",
      "--> data/lang/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 70 word/subword sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 86 word/subword sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang/oov.txt\n",
      "--> data/lang/oov.int corresponds to data/lang/oov.txt\n",
      "--> data/lang/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang/L.fst is olabel sorted\n",
      "--> data/lang/L_disambig.fst is olabel sorted\n",
      "--> SUCCESS [validating lang directory data/lang]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fstaddselfloops data/lang/phones/wdisambig_phones.int data/lang/phones/wdisambig_words.int \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./L_creation.sh'], returncode=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"./L_creation.sh\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50fc9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ac54ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort ./data/dev/dev_wav.scp -o ./data/dev/dev_wav.scp; sort ./data/dev/dev_text.txt -o ./data/dev/dev_text.txt; sort ./data/dev/dev_utt2spk.txt -o ./data/dev/dev_utt2spk.txt\n",
    "!sort ./data/train/train_wav.scp -o ./data/train/train_wav.scp; sort ./data/train/train_text.txt -o ./data/train/train_text.txt; sort ./data/train/train_utt2spk.txt -o ./data/train/train_utt2spk.txt\n",
    "!sort ./data/test/test_wav.scp -o ./data/test/test_wav.scp; sort ./data/test/test_text.txt -o ./data/test/test_text.txt; sort ./data/test/test_utt2spk.txt -o ./data/test/test_utt2spk.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f2ad2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4699f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./utils/utt2spk_to_spk2utt.pl ./data/train/train_utt2spk.txt > ./data/train/train_spk2utt.txt\n",
    "!./utils/utt2spk_to_spk2utt.pl ./data/dev/dev_utt2spk.txt > ./data/dev/dev_spk2utt.txt\n",
    "!./utils/utt2spk_to_spk2utt.pl ./data/test/test_utt2spk.txt > ./data/test/test_spk2utt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaf4faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e64d899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train, dev and test data\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/train\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/dev\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/test\n",
      "Preparing language models for test\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test_bg/words.txt - data/lang_test_bg/G.fst \n",
      "LOG (arpa2fst[5.5.1074~1-71f3]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.1074~1-71f3]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.1074~1-71f3]:Read():arpa-file-parser.cc:149) Reading \\2-grams: section.\n",
      "WARNING (arpa2fst[5.5.1074~1-71f3]:ConsumeNGram():arpa-lm-compiler.cc:313) line 52 [-2.82084\t<s> <s>] skipped: n-gram has invalid BOS/EOS placement\n",
      "LOG (arpa2fst[5.5.1074~1-71f3]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 42 to 42\n",
      "fstisstochastic data/lang_test_bg/G.fst \n",
      "0.00142338 -0.0828663\n",
      "utils/validate_lang.pl data/lang_test_bg\n",
      "Checking existence of separator file\n",
      "separator file data/lang_test_bg/subword_separator.txt is empty or does not exist, deal in word case.\n",
      "Checking data/lang_test_bg/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_test_bg/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_test_bg/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> found no unexplainable phones in phones.txt\n",
      "\n",
      "Checking data/lang_test_bg/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang_test_bg/phones/context_indep.txt\n",
      "--> data/lang_test_bg/phones/context_indep.int corresponds to data/lang_test_bg/phones/context_indep.txt\n",
      "--> data/lang_test_bg/phones/context_indep.csl corresponds to data/lang_test_bg/phones/context_indep.txt\n",
      "--> data/lang_test_bg/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 160 entry/entries in data/lang_test_bg/phones/nonsilence.txt\n",
      "--> data/lang_test_bg/phones/nonsilence.int corresponds to data/lang_test_bg/phones/nonsilence.txt\n",
      "--> data/lang_test_bg/phones/nonsilence.csl corresponds to data/lang_test_bg/phones/nonsilence.txt\n",
      "--> data/lang_test_bg/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang_test_bg/phones/silence.txt\n",
      "--> data/lang_test_bg/phones/silence.int corresponds to data/lang_test_bg/phones/silence.txt\n",
      "--> data/lang_test_bg/phones/silence.csl corresponds to data/lang_test_bg/phones/silence.txt\n",
      "--> data/lang_test_bg/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_test_bg/phones/optional_silence.txt\n",
      "--> data/lang_test_bg/phones/optional_silence.int corresponds to data/lang_test_bg/phones/optional_silence.txt\n",
      "--> data/lang_test_bg/phones/optional_silence.csl corresponds to data/lang_test_bg/phones/optional_silence.txt\n",
      "--> data/lang_test_bg/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 2 entry/entries in data/lang_test_bg/phones/disambig.txt\n",
      "--> data/lang_test_bg/phones/disambig.int corresponds to data/lang_test_bg/phones/disambig.txt\n",
      "--> data/lang_test_bg/phones/disambig.csl corresponds to data/lang_test_bg/phones/disambig.txt\n",
      "--> data/lang_test_bg/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_test_bg/phones/roots.txt\n",
      "--> data/lang_test_bg/phones/roots.int corresponds to data/lang_test_bg/phones/roots.txt\n",
      "--> data/lang_test_bg/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_test_bg/phones/sets.txt\n",
      "--> data/lang_test_bg/phones/sets.int corresponds to data/lang_test_bg/phones/sets.txt\n",
      "--> data/lang_test_bg/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 9 entry/entries in data/lang_test_bg/phones/extra_questions.txt\n",
      "--> data/lang_test_bg/phones/extra_questions.int corresponds to data/lang_test_bg/phones/extra_questions.txt\n",
      "--> data/lang_test_bg/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_test_bg/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 165 entry/entries in data/lang_test_bg/phones/word_boundary.txt\n",
      "--> data/lang_test_bg/phones/word_boundary.int corresponds to data/lang_test_bg/phones/word_boundary.txt\n",
      "--> data/lang_test_bg/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang_test_bg/phones/optional_silence.txt\n",
      "--> data/lang_test_bg/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang_test_bg/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang_test_bg/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang_test_bg/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang_test_bg/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang_test_bg/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang_test_bg/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 19 word/subword sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 61 word/subword sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang_test_bg/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_test_bg/oov.txt\n",
      "--> data/lang_test_bg/oov.int corresponds to data/lang_test_bg/oov.txt\n",
      "--> data/lang_test_bg/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang_test_bg/L.fst is olabel sorted\n",
      "--> data/lang_test_bg/L_disambig.fst is olabel sorted\n",
      "--> data/lang_test_bg/G.fst is ilabel sorted\n",
      "--> data/lang_test_bg/G.fst has 42 states\n",
      "fstdeterminizestar data/lang_test_bg/G.fst /dev/null \n",
      "--> data/lang_test_bg/G.fst is determinizable\n",
      "--> utils/lang/check_g_properties.pl successfully validated data/lang_test_bg/G.fst\n",
      "--> utils/lang/check_g_properties.pl succeeded.\n",
      "--> Testing determinizability of L_disambig . G\n",
      "fstdeterminizestar \n",
      "fsttablecompose data/lang_test_bg/L_disambig.fst data/lang_test_bg/G.fst \n",
      "--> L_disambig . G is determinizable\n",
      "--> SUCCESS [validating lang directory data/lang_test_bg]\n",
      "Succeeded in formatting data.\n"
     ]
    }
   ],
   "source": [
    "!./timit_format_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc1c5c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Calculating perplexity for the unigram model of the dev set #\n",
      "inpfile: uni_dev.ilm.gz\n",
      "outfile: uni_dev.ilm.blm\n",
      "evalfile: ../dict/lm_dev.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=4930 PP=32.23 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n",
      "# Calculating perplexity for the bigram model of the dev set #\n",
      "inpfile: bi_dev.ilm.gz\n",
      "outfile: bi_dev.ilm.blm\n",
      "evalfile: ../dict/lm_dev.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=4930 PP=12.47 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n",
      "# Calculating perplexity for the unigram model of the test set #\n",
      "inpfile: uni_test.ilm.gz\n",
      "outfile: uni_test.ilm.blm\n",
      "evalfile: ../dict/lm_test.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=12795 PP=31.87 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n",
      "# Calculating perplexity for the bigram model of the test set #\n",
      "inpfile: bi_test.ilm.gz\n",
      "outfile: bi_test.ilm.blm\n",
      "evalfile: ../dict/lm_test.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=12795 PP=13.26 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n"
     ]
    }
   ],
   "source": [
    "!./perplexity.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a2d0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9da3924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steps/make_mfcc.sh ./data/train\n",
      "./steps/make_mfcc.sh: moving ./data/train/feats.scp to ./data/train/.backup\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory ./data/train\n",
      "./steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "./steps/make_mfcc.sh: Succeeded creating MFCC features for train\n",
      "./steps/make_mfcc.sh ./data/test\n",
      "./steps/make_mfcc.sh: moving ./data/test/feats.scp to ./data/test/.backup\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory ./data/test\n",
      "./steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "./steps/make_mfcc.sh: Succeeded creating MFCC features for test\n",
      "./steps/make_mfcc.sh ./data/dev\n",
      "./steps/make_mfcc.sh: moving ./data/dev/feats.scp to ./data/dev/.backup\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory ./data/dev\n",
      "./steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "./steps/make_mfcc.sh: Succeeded creating MFCC features for dev\n"
     ]
    }
   ],
   "source": [
    "!./steps/make_mfcc.sh ./data/train\n",
    "!./steps/make_mfcc.sh ./data/test\n",
    "!./steps/make_mfcc.sh ./data/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd2c68e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steps/compute_cmvn_stats.sh ./data/train\n",
      "Succeeded creating CMVN stats for train\n",
      "./steps/compute_cmvn_stats.sh ./data/test\n",
      "Succeeded creating CMVN stats for test\n",
      "./steps/compute_cmvn_stats.sh ./data/dev\n",
      "Succeeded creating CMVN stats for dev\n"
     ]
    }
   ],
   "source": [
    "!./steps/compute_cmvn_stats.sh ./data/train # Cepstral Mean and Variance Normalization\n",
    "!./steps/compute_cmvn_stats.sh ./data/test\n",
    "!./steps/compute_cmvn_stats.sh ./data/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47cd6ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: feat-to-dim: command not found\n",
      "/bin/bash: feat-to-len: command not found\n",
      "f1_003 317 \n",
      "f1_004 371 \n",
      "f1_005 399 \n",
      "f1_007 328 \n",
      "f1_008 464 \n"
     ]
    }
   ],
   "source": [
    "!source ./path.sh\n",
    "\n",
    "!feat-to-dim scp:data/train/feats.scp - # dim of characteristics\n",
    "!feat-to-len scp:data/train/feats.scp ark,t:data/train/feats.lengths.txt #num of frames\n",
    "!head -5 data/train/feats.lengths.txt #print the first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19a009d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0c7b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./steps/train_mono.sh ./data/train ./data/lang_test_bg ./exp/mono_bg\n",
      "./steps/train_mono.sh: Initializing monophone system.\n",
      "./steps/train_mono.sh: Compiling training graphs\n",
      "./steps/train_mono.sh: Aligning data equally (pass 0)\n",
      "./steps/train_mono.sh: Pass 1\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 2\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 3\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 4\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 5\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 6\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 7\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 8\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 9\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 10\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 11\n",
      "./steps/train_mono.sh: Pass 12\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 13\n",
      "./steps/train_mono.sh: Pass 14\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 15\n",
      "./steps/train_mono.sh: Pass 16\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 17\n",
      "./steps/train_mono.sh: Pass 18\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 19\n",
      "./steps/train_mono.sh: Pass 20\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 21\n",
      "./steps/train_mono.sh: Pass 22\n",
      "./steps/train_mono.sh: Pass 23\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 24\n",
      "./steps/train_mono.sh: Pass 25\n",
      "./steps/train_mono.sh: Pass 26\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 27\n",
      "./steps/train_mono.sh: Pass 28\n",
      "./steps/train_mono.sh: Pass 29\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 30\n",
      "./steps/train_mono.sh: Pass 31\n",
      "./steps/train_mono.sh: Pass 32\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 33\n",
      "./steps/train_mono.sh: Pass 34\n",
      "./steps/train_mono.sh: Pass 35\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 36\n",
      "./steps/train_mono.sh: Pass 37\n",
      "./steps/train_mono.sh: Pass 38\n",
      "./steps/train_mono.sh: Aligning data\n",
      "./steps/train_mono.sh: Pass 39\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl ./data/lang_test_bg ./exp/mono_bg\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 30.599848139711465% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 27.107061503416855% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in ./exp/mono_bg/log/analyze_alignments.log\n",
      "191 warnings in ./exp/mono_bg/log/acc.*.*.log\n",
      "121 warnings in ./exp/mono_bg/log/update.*.log\n",
      "2714 warnings in ./exp/mono_bg/log/align.*.*.log\n",
      "2 warnings in ./exp/mono_bg/log/analyze_alignments.log\n",
      "6 warnings in ./exp/mono_bg/log/init.log\n",
      "./exp/mono_bg: nj=4 align prob=-83.61 over 1.66h [retry=1.3%, fail=0.2%] states=125 gauss=996\n",
      "./steps/train_mono.sh: Done training monophone system in ./exp/mono_bg\n"
     ]
    }
   ],
   "source": [
    "!./steps/train_mono.sh ./data/train ./data/lang_test_bg ./exp/mono_bg\n",
    "#align ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be2137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
