{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6a8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "\n",
    "import string\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f38fc",
   "metadata": {},
   "source": [
    "**Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd03bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data file\n",
    "\n",
    "# import tarfile\n",
    "\n",
    "# with tarfile.open(\"./usc.tgz\", \"r\") as tf:\n",
    "#    i=0\n",
    "#    for member in tf.getmembers():\n",
    "#        tf.extract(member=member, path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be008fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./usc/filesets/training.txt ./data/train/train_uttids.txt\n",
    "!cp ./usc/filesets/testing.txt ./data/test/test_uttids.txt\n",
    "!cp ./usc/filesets/validation.txt ./data/dev/val_uttids.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b96beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5882b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/train/train_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e5cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/test/test_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75081b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/val_utt2spk.txt\",'w') as f:\n",
    "    with open('./data/dev/val_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} {}\\n\".format(line[0:6],line[0:2]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139e3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e303cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_wav.scp\",'w') as f:\n",
    "    with open('./data/train/train_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a6f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_wav.scp\",'w') as f:\n",
    "    with open('./data/test/test_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1056e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/val_wav.scp\",'w') as f:\n",
    "    with open('./data/dev/val_uttids.txt') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write(\"{} ./usc/wav/{}.wav\\n\".format(line[0:6],line[0:6]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac956f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f508fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text,punct_list):\n",
    "    for punc in punct_list:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "s = string.punctuation\n",
    "punct_list = s.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd52f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_text.txt\",'w') as f:\n",
    "        with open('./data/train/train_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "244094b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_text.txt\",'w') as f:\n",
    "        with open('./data/test/test_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a61e1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/val_text.txt\",'w') as f:\n",
    "        with open('./data/dev/val_uttids.txt') as file:\n",
    "            # reading each uttid\n",
    "            for uttid in file:\n",
    "                # reading each transcription\n",
    "                with open(\"./usc/transcriptions.txt\") as g:\n",
    "                    for line in g:       \n",
    "                        num = line[0:3]\n",
    "                        text = line[4:-1]\n",
    "                        text = remove_punctuation(text,punct_list)\n",
    "                        if num == uttid[3:6]:\n",
    "                            f.write(\"{} {}\\n\".format(uttid[0:6],text.lower()))\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5229b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words --> phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca9dbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict = {}\n",
    "with open('./usc/lexicon.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        word = line.split()[0].lower()\n",
    "        phon = ''\n",
    "        for words in line.split()[1:-1]:\n",
    "            phon = phon + str(\"{} \".format(words)) \n",
    "        phon = phon + str(\"{}\".format(line.split()[-1])) \n",
    "        Dict[word] = phon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8d3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dev/val_text2.txt\",'w') as out_f:\n",
    "        with open('./data/dev/val_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abbfe862",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train/train_text2.txt\",'w') as out_f:\n",
    "        with open('./data/train/train_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94de5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test/test_text2.txt\",'w') as out_f:\n",
    "        with open('./data/test/test_text.txt','r') as f:\n",
    "            for line in f:\n",
    "                words = line.split()\n",
    "                out_f.write(words[0])\n",
    "                out_f.write(' sil ')\n",
    "                for word in words[1:]:\n",
    "                    out_f.write(\"{} \".format(Dict[word]))\n",
    "                out_f.write('sil\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69869bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"./data/train/train_text.txt\")\n",
    "os.remove(\"./data/test/test_text.txt\")\n",
    "os.remove(\"./data/dev/val_text.txt\")\n",
    "\n",
    "os.rename(\"./data/train/train_text2.txt\", \"./data/train/train_text.txt\")\n",
    "os.rename(\"./data/test/test_text2.txt\", \"./data/test/test_text.txt\")\n",
    "os.rename(\"./data/dev/val_text2.txt\", \"./data/dev/val_text.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d0348",
   "metadata": {},
   "source": [
    "**Main Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3d8a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link 'steps/steps': File exists\n",
      "ln: failed to create symbolic link 'utils/utils': File exists\n",
      "mkdir: cannot create directory ‘./local’: File exists\n",
      "ln: failed to create symbolic link './local/score_kaldi.sh': File exists\n",
      "mkdir: cannot create directory ‘./conf’: File exists\n",
      "mkdir: cannot create directory ‘./data/lang’: File exists\n",
      "mkdir: cannot create directory ‘./data/local’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/dict’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/lm_tmp’: File exists\n",
      "mkdir: cannot create directory ‘./data/local/nist_lm’: File exists\n",
      "total 76\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   698 Μαΐ  18 15:16 build.sh\n",
      "-rw-rw-r-- 1 tilemahos tilemahos  1318 Μαΐ  18 14:10 cmd.sh\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   300 Μαΐ  18 15:20 compile.sh\n",
      "drwxrwxr-x 2 tilemahos tilemahos  4096 Μαΐ  18 14:10 conf\n",
      "drwxrwxr-x 7 tilemahos tilemahos  4096 Μαΐ  18 14:10 data\n",
      "drwxrwxr-x 6 tilemahos tilemahos  4096 Μαΐ  18 14:10 jup_notebook\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   136 Μαΐ  18 17:59 L_creation.sh\n",
      "-rw-rw-r-- 1 tilemahos tilemahos     0 Μαΐ  18 14:10 lm\n",
      "drwxrwxr-x 3 tilemahos tilemahos  4096 Μαΐ  18 14:44 local\n",
      "-rwxrwxr-x 1 tilemahos tilemahos   449 Μαΐ  18 14:19 path.sh\n",
      "lrwxrwxrwx 1 tilemahos tilemahos    54 Μαΐ  18 14:18 steps -> /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/steps\n",
      "-rw-rw-r-- 1 tilemahos tilemahos  2127 Μαΐ  18 18:29 timit_format_data_1.sh\n",
      "-rwxrwxr-x 1 tilemahos tilemahos  2523 Μαΐ  18 14:10 timit_format_data.sh\n",
      "-rw-rw-r-- 1 tilemahos tilemahos 18304 Μαΐ  18 18:31 Untitled.ipynb\n",
      "drwxrwxr-x 4 tilemahos tilemahos  4096 Μαΐ  18 14:10 usc\n",
      "lrwxrwxrwx 1 tilemahos tilemahos    54 Μαΐ  18 14:18 utils -> /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/utils\n",
      "-rw-rw-r-- 1 tilemahos tilemahos  4144 Μαΐ  18 14:10 val_wav.scp\n"
     ]
    }
   ],
   "source": [
    "# 4.1\n",
    "\n",
    "# !!!!! Insert your path in path.sh and the commands below !!!!!\n",
    "\n",
    "# soft links\n",
    "!ln -s /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/steps steps # /home/anthi/jupyter/kaldi/egs/wsj/s5/steps steps \n",
    "!ln -s /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/utils utils # /home/anthi/jupyter/kaldi/egs/wsj/s5/utils utils\n",
    "\n",
    "!mkdir ./local\n",
    "!ln -s /home/tilemahos/Desktop/SLP_LAB/kaldi/egs/wsj/s5/steps/score_kaldi.sh ./local/score_kaldi.sh\n",
    "\n",
    "!mkdir ./conf\n",
    "!touch ./conf/mfcc.conf\n",
    "\n",
    "!mkdir ./data/lang\n",
    "!mkdir ./data/local\n",
    "!mkdir ./data/local/dict\n",
    "!mkdir ./data/local/lm_tmp\n",
    "!mkdir ./data/local/nist_lm\n",
    "\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce368782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.1\n",
    "\n",
    "with open(\"./data/local/dict/silence_phones.txt\",'w') as f:\n",
    "    f.write('sil\\n')\n",
    "    \n",
    "with open(\"./data/local/dict/optional_silence.txt\",'w') as f:\n",
    "    f.write('sil\\n')\n",
    "\n",
    "s = set()\n",
    "with open(\"./data/local/dict/nonsilence_phones.txt\",'w') as f:\n",
    "    with open('./usc/lexicon.txt', 'r') as file:\n",
    "        # reading each line   \n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split()[1:]:\n",
    "                if word not in s:\n",
    "                    s.add(word)\n",
    "        s.remove('sil')\n",
    "        l = list(s)\n",
    "        l.sort()\n",
    "        for phoneme in l:\n",
    "            f.write('{}\\n'.format(phoneme))\n",
    "\n",
    "with open(\"./data/local/dict/lexicon.txt\",'w') as f:\n",
    "    with open(\"./data/local/dict/nonsilence_phones.txt\",'r') as file:\n",
    "        # reading each line\n",
    "        for line in file:\n",
    "            # reading each word       \n",
    "            for word in line.split():\n",
    "                f.write('{} {}\\n'.format(word,word))\n",
    "        f.write('sil sil\\n')\n",
    "\n",
    "\n",
    "with open(\"./data/local/dict/lm_train.text\",'w') as out_f:\n",
    "    with open(\"./data/train/train_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "with open(\"./data/local/dict/lm_test.text\",'w') as out_f:\n",
    "    with open(\"./data/test/test_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "with open(\"./data/local/dict/lm_val.text\",'w') as out_f:\n",
    "    with open(\"./data/dev/val_text.txt\",'r') as f:\n",
    "        # reading each line\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            # out_f.write('{}'.format(l[0])) \n",
    "            out_f.write('<s>') \n",
    "            for word in l[1:]:\n",
    "                out_f.write(' {}'.format(word))\n",
    "            out_f.write(' </s>\\n') \n",
    "            \n",
    "!touch ./data/local/dict/extra_questions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "139402d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_train.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_train.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_test.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_test.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/uni_val.ilm.gz already exists! either remove or rename it.\n",
      "LOGFILE:/dev/null\n",
      "Output file ./data/local/lm_tmp/bi_val.ilm.gz already exists! either remove or rename it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./build.sh', 'arguments'], returncode=6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.2.2\n",
    "\n",
    "subprocess.run([\"./build.sh\",\n",
    "                \"arguments\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b86e06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d8a4e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inpfile: ./data/local/lm_tmp/uni_train.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 1362\n",
      "OOV code is 1362\n",
      "Saving in txt format to /dev/stdout\n",
      "inpfile: ./data/local/lm_tmp/bi_train.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 1362\n",
      "OOV code is 1362\n",
      "Saving in txt format to /dev/stdout\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./compile.sh', 'arguments'], returncode=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"./compile.sh\",\n",
    "                \"arguments\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4a5b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "145b41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tilemahos/Desktop/SLP_LAB/kaldi/egs/usc/utils/prepare_lang.sh ./data/local/dict <oov> ./data/local/lang data/lang\n",
      "Checking ./data/local/dict/silence_phones.txt ...\n",
      "--> reading ./data/local/dict/silence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/silence_phones.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/optional_silence.txt ...\n",
      "--> reading ./data/local/dict/optional_silence.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/optional_silence.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/nonsilence_phones.txt ...\n",
      "--> reading ./data/local/dict/nonsilence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/nonsilence_phones.txt is OK\n",
      "\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\n",
      "--> disjoint property is OK.\n",
      "\n",
      "Checking ./data/local/dict/lexicon.txt\n",
      "--> reading ./data/local/dict/lexicon.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/lexicon.txt is OK\n",
      "\n",
      "Checking ./data/local/dict/lexiconp.txt\n",
      "--> reading ./data/local/dict/lexiconp.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> ./data/local/dict/lexiconp.txt is OK\n",
      "\n",
      "Checking lexicon pair ./data/local/dict/lexicon.txt and ./data/local/dict/lexiconp.txt\n",
      "--> lexicon pair ./data/local/dict/lexicon.txt and ./data/local/dict/lexiconp.txt match\n",
      "\n",
      "Checking ./data/local/dict/extra_questions.txt ...\n",
      "--> ./data/local/dict/extra_questions.txt is empty (this is OK)\n",
      "--> SUCCESS [validating dictionary directory ./data/local/dict]\n",
      "\n",
      "prepare_lang.sh: validating output directory\n",
      "utils/validate_lang.pl data/lang\n",
      "Checking existence of separator file\n",
      "separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.\n",
      "Checking data/lang/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> found no unexplainable phones in phones.txt\n",
      "\n",
      "Checking data/lang/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 160 entry/entries in data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 2 entry/entries in data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang/phones/roots.txt\n",
      "--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt\n",
      "--> data/lang/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang/phones/sets.txt\n",
      "--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt\n",
      "--> data/lang/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 9 entry/entries in data/lang/phones/extra_questions.txt\n",
      "--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt\n",
      "--> data/lang/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 165 entry/entries in data/lang/phones/word_boundary.txt\n",
      "--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt\n",
      "--> data/lang/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 54 word/subword sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 22 word/subword sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang/oov.txt\n",
      "--> data/lang/oov.int corresponds to data/lang/oov.txt\n",
      "--> data/lang/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang/L.fst is olabel sorted\n",
      "--> data/lang/L_disambig.fst is olabel sorted\n",
      "--> SUCCESS [validating lang directory data/lang]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fstaddselfloops data/lang/phones/wdisambig_phones.int data/lang/phones/wdisambig_words.int \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./L_creation.sh'], returncode=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"./L_creation.sh\"], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50fc9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ac54ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort ./data/dev/val_wav.scp -o ./data/dev/val_wav.scp; sort ./data/dev/val_text.txt -o ./data/dev/val_text.txt; sort ./data/dev/val_utt2spk.txt -o ./data/dev/val_utt2spk.txt\n",
    "!sort ./data/train/train_wav.scp -o ./data/train/train_wav.scp; sort ./data/train/train_text.txt -o ./data/train/train_text.txt; sort ./data/train/train_utt2spk.txt -o ./data/train/train_utt2spk.txt\n",
    "!sort ./data/test/test_wav.scp -o ./data/test/test_wav.scp; sort ./data/test/test_text.txt -o ./data/test/test_text.txt; sort ./data/test/test_utt2spk.txt -o ./data/test/test_utt2spk.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f2ad2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4699f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./utils/utt2spk_to_spk2utt.pl ./data/train/train_utt2spk.txt > ./data/train/train_spk2utt.txt\n",
    "!./utils/utt2spk_to_spk2utt.pl ./data/dev/val_utt2spk.txt > ./data/dev/val_spk2utt.txt\n",
    "!./utils/utt2spk_to_spk2utt.pl ./data/test/test_utt2spk.txt > ./data/test/test_spk2utt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaf4faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e64d899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train, dev and test data\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/train\n",
      "cp: cannot stat 'data/dev/dev_wav.scp': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!./timit_format_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c5c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
